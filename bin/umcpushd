#!/usr/bin/env python2
# -*- coding: utf-8 -*-
#
# umcpush daemon - a tool to push data from csv logs generated by umcrunner to various destinations such as influxdb or OMC
# 06-2018, Tomas Vitvar, tomas@vitvar.com

# TODO: 
# - do not recalculate milis values, does not work when overiding params (e.g. delay-run, wait when failure occurs)
# - write to the destination only when the write buffer is full on maximum intervals of X seconds/minute

import os
import sys
import signal
import yaml
import datetime
import csv
import re
import socket
import time
import argparse
import messages as Msg
import utils
import umcwriter

from time import gmtime, strftime
from threading import Event
from utils import Map
from umcconfig import UmcConfig
from umcreader import UmcReader
from umcwriter import UmcWriter

from requests.exceptions import *

# global context
class GlobalContext():
    id=None                 # id of the push tool
    configFile=None         # configuration file
    confing=None            # UmcConfig object
    lastwritecall = time.time() # last time the db was accessed
    exit = Event()          # exit event to correctly terminate the process
    lasterror=None          # last error text
    lasterrorcount=0        # last error count

# data buffer class
class Buffer(object):
    def __init__(self):
        self.countRecords=0
        self.countFiles=0
        self.datapoints=[]
        self.datafiles=[]
    
    def reset(self, counters=False):
        self.countRecords+=len(self.datapoints)
        self.countFiles+=len(self.datafiles)
        self.datapoints=[]
        self.datafiles=[]
        
        if counters:
            self.countRecords=0
            self.countFiles=0
    # // reset
# // Buffer

# gets a lock using domain sockets to prevent this script from running more than once
def get_lock(writerid):
    get_lock._lock_socket = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM)
    try:
        get_lock._lock_socket.bind('\0umcpush-magic-aw422d5522dft5saxg5_' + writerid)
        return True
    except socket.error:
        return False
# // get_lock

# signal termination handler for graceful shutdown
def signal_quit(signal, frame):
    Msg.warn_msg("Shutting down...")
    GlobalContext.exit.set()

# writes the data to the destination; retries when not successful
def write(GlobalContext, datapoints, datafiles,try_once=False):    
    # wait between db writes
    secs=time.time()
    if GlobalContext.lastwritecall > 0 and (secs - GlobalContext.lastwritecall < GlobalContext.writer.params.delay_writes):
        GlobalContext.exit.wait((GlobalContext.writer.params.delay_writes - (secs - GlobalContext.lastwritecall)))

    retryCount=0
    while not GlobalContext.exit.is_set():
        retry = False                    
        try:
            # write the points and update the last db call time
            response = GlobalContext.writer.write(datapoints, GlobalContext.exit)
            GlobalContext.lastwritecall = time.time()
            if retryCount > 0:
                Msg.info1_msg("The connection to the writer's destination was successful after %d retries."%retryCount);
        except (ConnectionError, Timeout) as e:
            Msg.err_msg("Error occurred when inserting data: %s"%(e))     
            if try_once:
                return False
                                                               
            if (GlobalContext.writer.params.connection_retry_count == -1 or retryCount < GlobalContext.writer.params.connection_retry_count):
                Msg.err_msg("Will retry in %d seconds..."%(GlobalContext.writer.params.connection_retry_interval))                            
                GlobalContext.exit.wait(GlobalContext.writer.params.connection_retry_interval)
                if GlobalContext.exit.is_set():
                    return False
                retryCount=retryCount+1
                retry = True
            else:
                # this will make the umcpush exit
                raise Exception("Maximum number of %d retries reached!"%(retryCount))                          
        except Exception as e:
            Msg.err_msg("Error occurred when inserting data, all records in the write buffer (%d) will be discarded!: %s"
                %(len(datapoints),str(e)))
            retry = False
            pass                                                    
            
        if not(retry):
            removeFiles(datafiles)
            break # break the retry loop
    # // end retry loop
    
    return True   
# // write

# remove all files from the list datafiles
def removeFiles(datafiles):
    for file in datafiles:
        try:
            os.remove(file)
        except Exception as e:
            Msg.err_msg("Cannot remove file due to %s"%str(e))
# // removeFiles             
    
# *** MAIN
if __name__ == "__main__":    
    # arguments
    parser = argparse.ArgumentParser(description="push csv logs files to a writer's destination generated by umcrunner")
    parser.add_argument('--writer', required=True, help='a valid writer id')
    parser.add_argument('--config', required=False, help='configuration file <file>',metavar='<file>')
    parser.add_argument('--logs', required=False, help='location of umc logs directory',metavar='<dir>')
    parser.add_argument('--verbose', required=False, help='be verbose',action='store_true')
    args=parser.parse_args()
    Msg.verbose=args.verbose
    
    # get the lock and exit when already running
    if not(get_lock(args.writer)):
        sys.exit(1)

    # register signals to quit the process
    for sig in ('TERM', 'HUP', 'INT'):
        signal.signal(getattr(signal, 'SIG'+sig), signal_quit);

    try:
        # create the main configuration object
        GlobalContext.writer_id=args.writer
        GlobalContext.config=UmcConfig(GlobalContext.configFile, args.logs)
        Msg.info2_msg("Using configuration file %s"%GlobalContext.config.configFile)
        Msg.info2_msg("The logs directory is in %s"%GlobalContext.config.logDir)

        # storage of umc definitions from the configuration file
        umcdefs = {}
        
        # write buffer 
        buffer=Buffer()
    
        # instantiate reader and writer objects
        GlobalContext.writer=umcwriter.create_instance(GlobalContext.config, GlobalContext.writer_id)        
        GlobalContext.reader=UmcReader(GlobalContext.config, GlobalContext.writer.writer_id)
        
        # welcome message
        Msg.info1_msg("umcpush started with writer id '%s'."%(GlobalContext.writer.writer_id))

        # show writer and reader params
        Msg.info2_msg("reader params: %s"%(GlobalContext.reader.params))
        Msg.info2_msg("writer params: %s"%(GlobalContext.writer.params))

        # read all umcdefs from the config file
        umcdefs=GlobalContext.config.read_umcdefs(GlobalContext.reader, GlobalContext.writer)
        umc_instanceids=[ k for k,v in umcdefs.items() if v.enabled ]
        Msg.info1_msg("The following umc instances are enabled: %s"%umc_instanceids )

        # main umcpush tool
        while not GlobalContext.exit.is_set():
            # retrieve logs in a batch of maximum NUM files
            batchlogs=GlobalContext.reader.get_batch_logs(GlobalContext.config.logDir,umc_instanceids,buffer.datafiles)
            Msg.info1_msg("A batch of %d log files loaded."%(len(batchlogs)))
            
            # process all files in the batch
            start_time = time.time()    
            while len(batchlogs) > 0 and not GlobalContext.exit.is_set():
                logfile=batchlogs.pop()
                
                # check if the file exists
                if not(os.path.exists(logfile)):
                    Msg.err_msg("The file %s does not exist, is there another process working in logs directory?"%logfile)
                    continue
                
                # read and check umc definition for this file
                umc_id = GlobalContext.config.get_umcid_from_logfile(logfile)        
                if umc_id is None:
                    Msg.err_msg("Cannot determine umc_id from the log file %s, skipping this file."%logfile)                    
                    continue
                
                # process this umcdef if enabled
                if umcdefs[umc_id].enabled: 
                    # read datapoints from the log file and store them in the umcdef dict
                    buffer.datapoints += GlobalContext.reader.read_datapoints(logfile,umcdefs[umc_id], GlobalContext.writer.createWriteItem)
                    buffer.datafiles.append(logfile)
                    Msg.info2_msg("Data points read for umc %s. There is currently %d records in %d files in the write buffer."
                        %(umc_id,len(buffer.datapoints),len(buffer.datafiles)))        
                    
                    # write points in batches of max_batchsize_rows
                    if len(buffer.datapoints) > 0 and (len(buffer.datapoints)/GlobalContext.reader.params.max_batchsize_rows >= 1 \
                     or (GlobalContext.writer.params.write_interval>0 and GlobalContext.lastwritecall>0 and time.time()-GlobalContext.lastwritecall>GlobalContext.writer.params.write_interval)):
                        write(GlobalContext, buffer.datapoints, buffer.datafiles)
                        Msg.info1_msg("Write buffer flushed (%d records from %d files)."
                            %(len(buffer.datapoints),len(buffer.datafiles)))  
                        buffer.reset()      
                    # // batch write
                # // enabled
            # // end log files iteration
            
            # flush the remaining write buffer
            nonemptybuffer_delete=True
            if len(buffer.datapoints) > 0:
                if GlobalContext.writer.params.write_interval==0 or (GlobalContext.lastwritecall>0 and time.time()-GlobalContext.lastwritecall>GlobalContext.writer.params.write_interval) \
                 or len(buffer.datapoints)/GlobalContext.reader.params.max_batchsize_rows >= 1:
                    write(GlobalContext, buffer.datapoints, buffer.datafiles)
                    Msg.info1_msg("Remaining write buffer flushed (%d records from %d files)."
                        %(len(buffer.datapoints), len(buffer.datafiles)))
                    buffer.reset(counters=True)
                else:
                  Msg.info2_msg("There is remaining data in the write buffer but the write_interval of %s seconds has not elapsed, %s seconds are remaining."%(GlobalContext.writer.params.write_interval, GlobalContext.writer.params.write_interval-(time.time()-GlobalContext.lastwritecall)))
                  nonemptybuffer_delete=False
                # remaining batch write
            # len datapoints > 0

            # clear the buffer
            if len(buffer.datafiles) > 0 and nonemptybuffer_delete:
                Msg.info1_msg("There is still %d datafiles in the write buffer that apparently do not provide any data; removing them all..."
                    %len(buffer.datafiles))
                removeFiles(buffer.datafiles)
                buffer.reset(counters=True)
            # // if datafiles exist        
                            
            # wait between runs
            if not GlobalContext.exit.is_set(): 
                Msg.info2_msg("Waiting %s seconds to start the next iteration."%(GlobalContext.writer.params.delay_runs))
                GlobalContext.exit.wait(GlobalContext.writer.params.delay_runs)
            
        # // end main loop
        
        # flush the remaining write buffer on exit
        if len(buffer.datapoints) > 0: 
            GlobalContext.exit.clear()
            if write(GlobalContext, buffer.datapoints, buffer.datafiles, try_once=True):
                Msg.info1_msg("Remaining write buffer flushed on exit (%d records from %d files)."
                    %(len(buffer.datapoints), len(buffer.datafiles)))  
            else:
                Msg.err_msg("Flushing of the buffer failed; all %d records from %d files will be discarded!"
                    %(len(buffer.datapoints), len(buffer.datafiles)))
            buffer.reset(counters=True)
        # buffer flush
        
        # bye bye message
        Msg.info1_msg("umcpush gracefully ended.")
        
    except Exception as e:
        Msg.err_msg("Failed due to error: %s"%e)
        raise

